Modular Synthetic Data Generation Factory for LLM Training Pipelines

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://genesis-lab-dfxa5n7gkykdk9bc8uhfpn.streamlit.app)

**Live Demo:** https://genesis-lab-dfxa5n7gkykdk9bc8uhfpn.streamlit.app

GENESIS-LAB es un framework modular diseÃ±ado para crear, evaluar y administrar datasets sintÃ©ticos de alta calidad utilizando AWS Bedrock, pipelines con LLMs, y una arquitectura escalable basada en principios modernos de ingenierÃ­a de datos y agentes.

El proyecto funciona como una fÃ¡brica de datasets sintÃ©ticos, permitiendo:
- GeneraciÃ³n controlada y reproducible
- ValidaciÃ³n estadÃ­stica y semÃ¡ntica
- Entrenamiento incremental
- Registro y versionamiento de datasets
- ExposiciÃ³n vÃ­a UI para uso interno y demo

âš™ï¸ Arquitectura del Proyecto
El proyecto estÃ¡ organizado en una estructura modular:

genesis-lab/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ generation/      # GeneraciÃ³n sintÃ©tica (prompts, pipelines, Bedrock)
â”‚   â”œâ”€â”€ training/        # Rutinas para entrenamiento incremental
â”‚   â”œâ”€â”€ validation/      # MÃ©tricas, calidad, distribuciÃ³n, sesgos
â”‚   â”œâ”€â”€ registry/        # Registro y versionado de datasets
â”‚   â”œâ”€â”€ utils/           # Config, cliente AWS, helpers
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ pages/           # Pages de Streamlit
â”‚   â””â”€â”€ app.py           # UI principal
â”‚
â”œâ”€â”€ models/              # Modelos entrenados o checkpoints internos (vacÃ­o por .gitignore)
â”œâ”€â”€ data/                # Datasets locales (excluidos del repo)
â”œâ”€â”€ docs/                # DocumentaciÃ³n tÃ©cnica
â”‚
â”œâ”€â”€ .cursorrules         # Reglas del IDE asistido por IA
â”œâ”€â”€ .env.template        # Variables requeridas (sin secretos)
â”œâ”€â”€ pyproject.toml       # Dependencias del proyecto
â””â”€â”€ README.md

ğŸš€ Objetivos Principales
- Crear un sistema automatizado para la fabricaciÃ³n de datasets sintÃ©ticos.
- DiseÃ±ar pipelines reproducibles con AWS Bedrock y modelos LLM.
- Implementar mÃ©tricas de calidad, distribuciÃ³n y sesgos para validaciÃ³n.
- Construir una UI interactiva para orquestar y visualizar procesos.
- Mantener una arquitectura expansible para nuevos mÃ³dulos y agentes.

ğŸ”§ InstalaciÃ³n
1. Clonar el repositorio
git clone https://github.com/ilsantino/genesis-lab.git
cd genesis-lab

2. Crear entorno con uv
uv venv
uv sync

3. Crear archivo .env
Usa como referencia: cp .env.template .env

Rellena:
AWS_ACCESS_KEY_ID=...
AWS_SECRET_ACCESS_KEY=...
AWS_REGION=us-east-1

Nunca subas tu .env al repo.

## ğŸš€ Quick Start

```bash
# Generar 10 conversaciones de prueba
uv run python scripts/generate_data.py --total 10 --delay 3

# Generar 100 conversaciones bilingÃ¼es (~1.5h)
uv run python scripts/generate_data.py --total 100

# GeneraciÃ³n overnight (500 items con auto-pause)
uv run python scripts/generate_data.py --total 500 --max-failures 10

# Resumir generaciÃ³n interrumpida
uv run python scripts/generate_data.py --total 500 --resume

# Ver plan sin generar (dry run)
uv run python scripts/generate_data.py --total 100 --dry-run

# Validar calidad del dataset
uv run python scripts/validate_100.py

# Entrenar clasificador de intents
uv run python -m src.training.intent_classifier

# Health check del sistema
uv run python scripts/health_check.py
```

## UI Streamlit

Ejecutar: `uv run streamlit run ui/app.py`

### PÃ¡ginas disponibles:
- **Home** - Dashboard con dominios y mÃ©tricas
- **Generate** - ConfiguraciÃ³n y generaciÃ³n de datos sintÃ©ticos
- **Validate** - AnÃ¡lisis de calidad, sesgos y distribuciones
- **Training** - Entrenamiento de clasificadores con presets y CV
- **Registry** - Browse, search y export de datasets
- **Compare** - ComparaciÃ³n side-by-side de datasets
- **Help** - DocumentaciÃ³n completa del sistema

### CaracterÃ­sticas:
- Tema oscuro con glassmorphism
- 12 componentes UI reutilizables
- 9 charts interactivos (Plotly)
- DiseÃ±o responsivo
- Estados de carga y error

ğŸ§± MÃ³dulos Principales
1. generation/
Pipelines para creaciÃ³n sintÃ©tica:
- Templates de prompts
- Flujos con LLMs (Bedrock u otros modelos)
- Controladores de distribuciÃ³n y volumen

2. validation/
MÃ©tricas clave incluidas:
- DistribuciÃ³n estadÃ­stica
- Sesgo semÃ¡ntico
- Calidad lingÃ¼Ã­stica
- Divergencia vs dataset real

3. training/
Rutinas para:
- Entrenamiento incremental
- EvaluaciÃ³n
- ExportaciÃ³n de checkpoints (localmente, no en repo)

4. registry/
GestiÃ³n del dataset fabricado:
- Versioning
- Metadata
- ExportaciÃ³n a S3 o local

ğŸ§ª Tests
Ubicados en:tests/

Incluye pruebas unitarias para:
Funciones clave de generaciÃ³n
Validaciones estadÃ­sticas
IntegraciÃ³n de pipelines

ğŸ“„ DocumentaciÃ³n
Toda la documentaciÃ³n del sistema estÃ¡ en:

docs/
â”œâ”€â”€ ARCHITECTURE.md
â”œâ”€â”€ DEVLOG.md
â”œâ”€â”€ PROJECTSTATUS.md
â”œâ”€â”€ ROADMAP.md
â””â”€â”€ TDR.md

## MÃ©tricas Actuales (DÃ­a 4)

| MÃ©trica | Valor |
|---------|-------|
| Conversaciones generadas | 100 |
| Intents cubiertos | 77/77 (100%) |
| Quality score | 81.3/100 |
| Idiomas | 50% EN / 50% ES |
| Costo por conversaciÃ³n | ~$0.01 |

## Roadmap (High Level)

- [x] IntegraciÃ³n Bedrock completa
- [x] Sistema de scoring de calidad
- [x] ValidaciÃ³n de sesgos
- [x] Dataset Registry (SQLite)
- [x] Intent Classifier baseline
- [x] **UI Streamlit completa** (Dashboard, Generate, Validate, Registry, Compare)
- [x] **Dashboard comparativo de datasets**
- [x] **Sistema de componentes UI reutilizables**
- [x] **DiseÃ±o responsivo con tema oscuro**
- [ ] Escalar a 1K+ conversaciones (esperando AWS quota)
- [ ] Agente autÃ³nomo para iterar datasets
- [ ] Entrenamiento RLHF
- [ ] Export direct to S3 + version control
- [ ] MÃ©tricas de fairness mÃ¡s avanzadas

ğŸ‘¤ Autor

Santiago Ãlvarez (Santino)
Founder & CEO, iaGO
AI-first innovation, automation & synthetic intelligence systems.
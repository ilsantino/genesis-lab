# GENESIS-LAB â€” Development Log (DEVLOG)

Este documento registra todos los avances diarios del proyecto GENESIS-LAB.  
Corresponde al DÃ­a 1 de trabajo consolidado.

---

## ðŸ“… DÃ­a 0 â€” Setup inicial, arquitectura y configuraciÃ³n AWS

### ðŸ”§ ConfiguraciÃ³n del entorno
- CreaciÃ³n de estructura base del proyecto: `src/`, `ui/`, `tests/`, `data/`, `models/`, `notebooks/`.
- ConfiguraciÃ³n de `pyproject.toml` como gestor principal de dependencias (usando uv).
- CreaciÃ³n de `.cursorrules` para estandarizar estilo, arquitectura y comportamiento de la IA asistente.
- InstalaciÃ³n de dependencias iniciales:
  - boto3  
  - streamlit  
  - python-dotenv  
  - pandas  
  - numpy
- CreaciÃ³n del entorno virtual usando `uv`.

### â˜ï¸ AWS Setup completo
- CreaciÃ³n de IAM User: `genesis-lab-dev-ilsantino`.
- CreaciÃ³n de IAM Group con permisos mÃ­nimos:
  - AmazonBedrockFullAccess  
  - AmazonS3FullAccess
- GeneraciÃ³n de Access Key y Secret Key.
- InstalaciÃ³n correcta de AWS CLI v2 (solucionando problemas de PATH).
- ConfiguraciÃ³n de credenciales vÃ­a `aws configure`.
- Ajuste de regiÃ³n a `us-east-1`.
- ValidaciÃ³n satisfactoria de Bedrock con: aws bedrock list-foundation-models --region us-east-1

### ðŸ”— GitHub Setup
- CreaciÃ³n del repositorio remoto.
- InicializaciÃ³n de Git local.
- ResoluciÃ³n del error â€œfetch firstâ€ al hacer push.
- SincronizaciÃ³n correcta del repo.

### ðŸ–¥ UI Base
- CreaciÃ³n de `ui/app.py` y estructura inicial de pÃ¡ginas en `ui/pages/`.
- ConfirmaciÃ³n de que Streamlit no requiere extensiÃ³n en Cursor.

### ðŸ§± Decisiones ArquitectÃ³nicas
- Uso de arquitectura modular en `src/`.
- SeparaciÃ³n estricta por responsabilidad.
- Nada de hardcodear secretos (uso obligatorio de `.env + config.py`).
- Bedrock como proveedor principal.
- Streamlit como UI inicial.
- Llama/Nova como modelos temporales hasta aprobaciÃ³n de Claude.

---

## Estado actual del proyecto
- Entorno completamente funcional.
- AWS funcionando y Bedrock accesible.
- Proyecto inicializado con arquitectura limpia.
- Repo conectado a GitHub.
- UI bÃ¡sica creada.

---
# GENESIS-LAB - Project Status

## DÃ­a 1 Completado - Schemas, Reference Datasets, y Templates

Fecha: 2024-12-16

### Resumen Ejecutivo

Hemos completado exitosamente la fase de fundaciÃ³n del proyecto, estableciendo todos los schemas de datos, descargando datasets de referencia de HuggingFace, y creando templates de prompts bilingÃ¼es expandidos. Las mejoras estratÃ©gicas realizadas durante la implementaciÃ³n han elevado significativamente la calidad tÃ©cnica del proyecto mÃ¡s allÃ¡ del plan original.

---

### Schemas de Datos Implementados

Creamos el archivo src slash generation slash schemas punto py con modelos Pydantic que definen la estructura de datos para todos los dominios del proyecto. Para el dominio de customer service, implementamos la clase CustomerServiceConversation que valida conversaciones multi-turn con diez intents diferentes, tres niveles de sentiment, y validaciÃ³n automÃ¡tica de que la primera interacciÃ³n siempre sea del cliente. Para el dominio de series temporales, implementamos la clase TimeSeries que valida series temporales con seis tipos diferentes de series, cuatro frecuencias posibles, y validaciÃ³n automÃ¡tica de que los timestamps estÃ©n ordenados cronolÃ³gicamente.

Adicionalmente definimos schemas para mÃ©tricas de calidad con QualityMetrics que incluye scores de completeness, consistency, realism y diversity, y para mÃ©tricas de bias con BiasMetrics que incluye distribuciÃ³n demogrÃ¡fica, distribuciÃ³n de sentimiento, y cobertura de tÃ³picos. Finalmente creamos DatasetMetadata para el registro de datasets con informaciÃ³n de generaciÃ³n, mÃ©tricas de calidad, mÃ©tricas de bias, y resultados de entrenamiento.

El tercer dominio financiero estÃ¡ documentado arquitecturalmente con FinancialTransaction pero no estÃ¡ implementado en el MVP, siguiendo la decisiÃ³n estratÃ©gica de profundizar en dos dominios en lugar de implementar superficialmente tres.

---

### Reference Datasets Descargados

Descargamos exitosamente dos datasets de referencia desde HuggingFace que usaremos para validaciÃ³n de calidad y detecciÃ³n de bias. Para customer service descargamos quinientos ejemplos del dataset banking77 que contiene consultas de servicios bancarios digitales clasificadas en setenta y siete intents diferentes. Este dataset se guardÃ³ en data slash reference slash customer_service_reference punto json.

Para series temporales inicialmente planeamos usar ETDataset slash ett, pero identificamos durante la implementaciÃ³n que este dataset solo contenÃ­a dos series correlacionadas del mismo transformador elÃ©ctrico, lo cual era insuficiente para validaciÃ³n estadÃ­stica robusta. Tomamos la decisiÃ³n estratÃ©gica de cambiar a LeoTungAnh slash electricity_hourly, que proporciona trescientas setenta series independientes de consumo elÃ©ctrico de hogares portugueses reales. Descargamos cien series de las trescientas setenta disponibles, con quinientos puntos temporales cada una, y las guardamos en data slash reference slash timeseries_reference punto json.

Este cambio de dataset fue crÃ­tico porque con solo dos series correlacionadas no podÃ­amos calcular distribuciones estadÃ­sticas significativas ni validar diversidad entre mÃºltiples series sintÃ©ticas generadas. Con cien series independientes, el sistema de validaciÃ³n podrÃ¡ comparar robustamente si los datos sintÃ©ticos muestran la misma variabilidad y patrones que datos reales de mÃºltiples entidades independientes.

---

### Templates de Prompts - Customer Service

Creamos src slash generation slash templates slash customer_service_prompts punto py con templates bilingÃ¼es expandidos que superan significativamente el diseÃ±o original. En lugar de los diez intents genÃ©ricos planificados, integramos los setenta y siete intents de banking77 organizados en once categorÃ­as funcionales, lo cual permite que nuestros datos sintÃ©ticos sean directamente comparables con el dataset de referencia durante la validaciÃ³n.

Implementamos bilingÃ¼ismo completo con system prompts en inglÃ©s y espaÃ±ol, y diez few-shot examples de alta calidad, cinco en cada idioma. El tono fue ajustado de corporativo tradicional a estilo neobank o fintech digital, reflejando que banking77 proviene de contexto de banca digital moderna similar a Revolut o Nubank, no de banca tradicional. Esta coherencia tonal es crÃ­tica para que los datos sintÃ©ticos sean realistas cuando se comparen con el reference dataset.

Expandimos el schema de conversaciones de cinco campos a once campos, agregando category para agrupar los setenta y siete intents, complexity con tres niveles, customer_emotion_arc para tracking de evoluciÃ³n emocional durante la conversaciÃ³n, y resolution_time_category para clasificar la eficiencia de resoluciÃ³n en instant, quick, standard o extended.

Implementamos validaciÃ³n built-in con las funciones validate_intent y validate_conversation_schema, siguiendo arquitectura de producciÃ³n donde validamos en el punto de generaciÃ³n para prevenir errores downstream. TambiÃ©n agregamos build_batch_prompt para generar mÃºltiples conversaciones en una sola llamada al LLM, optimizando costos de AWS Bedrock.

---

### Templates de Prompts - Time Series

Creamos src slash generation slash templates slash timeseries_prompts punto py con una estructura similar pero adaptada a datos numÃ©ricos temporales. Expandimos de seis tipos genÃ©ricos a cuatro dominios estructurados con diecisÃ©is series types: electricity con cincuenta por ciento del peso incluyendo residential_consumption y grid_demand, energy con veinte por ciento incluyendo solar_generation y wind_generation, sensors con veinte por ciento incluyendo temperature y pressure, y financial con diez por ciento incluyendo stock_price y crypto_price.

Implementamos bilingÃ¼ismo con system prompts y diez few-shot examples, cinco en inglÃ©s y cinco en espaÃ±ol. Expandimos el schema de series temporales de siete campos a diecisiete campos, agregando seasonality_types para especificar mÃºltiples tipos de estacionalidad simultÃ¡neos, trend_type para clasificar tendencias, anomaly_types para especificar tipos de anomalÃ­as presentes, y domain_context para informaciÃ³n especÃ­fica del dominio.

Cambiamos el formato target de lista de objetos con timestamp y value a lista simple de valores numÃ©ricos, haciÃ©ndolo compatible con el formato estÃ¡ndar de HuggingFace que usa nuestro reference dataset. Esto permite comparaciÃ³n directa durante validaciÃ³n sin necesidad de transformaciones intermedias.

Implementamos tres funciones de validaciÃ³n: validate_series_type para verificar que el tipo de serie sea vÃ¡lido, validate_timeseries_schema para verificar la estructura del output, y validate_temporal_consistency para verificar que los timestamps estÃ©n correctamente espaciados y los patrones temporales sean coherentes.

---

### ConfiguraciÃ³n Centralizada

Actualizamos src slash utils slash config punto py con configuraciÃ³n detallada por dominio. Para customer service especificamos el reference dataset como banking77, los diez intents originales mÃ¡s una nota de que los templates usan setenta y siete intents, y parÃ¡metros de generaciÃ³n con temperature cero punto siete, max_tokens mil, y top_p cero punto nueve.

Para time series especificamos el reference dataset como electricity, los seis series types con frecuencias de one minute, five minutes, one hour y one day, y parÃ¡metros de generaciÃ³n con temperature mÃ¡s baja de cero punto cinco para mayor consistencia numÃ©rica, max_tokens dos mil, y top_p cero punto ochenta y cinco.

Configuramos thresholds de validaciÃ³n con mÃ­nimos de noventa y cinco por ciento para completeness, noventa por ciento para consistency, ochenta y cinco por ciento para realism, ochenta por ciento para diversity, y ochenta y cinco puntos cero para overall quality score. Para bias detection establecimos mÃ¡ximo de cero punto tres para sentiment imbalance y mÃ­nimo de cero punto siete para topic coverage.

Definimos la configuraciÃ³n de training con test size de veinte por ciento, validation size de diez por ciento, random state cuarenta y dos, y modelos habilitados incluyendo logistic regression y xgboost, dejando random forest deshabilitado para el MVP.

---

### Decisiones EstratÃ©gicas Clave

Durante la implementaciÃ³n tomamos varias decisiones estratÃ©gicas que mejoraron significativamente el proyecto. La primera fue integrar completamente los setenta y siete intents de banking77 en lugar de usar diez intents genÃ©ricos, lo cual alinea la generaciÃ³n sintÃ©tica con el dataset de referencia usado en evaluaciÃ³n, facilitando comparaciones directas y validaciÃ³n rigurosa.

La segunda decisiÃ³n fue implementar bilingÃ¼ismo completo en inglÃ©s y espaÃ±ol, reconociendo que MÃ©xico y EspaÃ±a son mercados objetivo de iaGO y que proyectos bilingÃ¼es son raros y valiosos en portfolios acadÃ©micos. Esto agrega complejidad tÃ©cnica pero tambiÃ©n demuestra capacidad de trabajar con mÃºltiples idiomas.

La tercera decisiÃ³n fue cambiar de ETT a electricity_hourly para series temporales, basada en el anÃ¡lisis crÃ­tico de que dos series correlacionadas eran insuficientes para validaciÃ³n estadÃ­stica robusta. Este cambio asegura que podemos validar adecuadamente la diversidad y realismo de datos sintÃ©ticos generados.

La cuarta decisiÃ³n fue ajustar el tono de corporativo a neobank o fintech digital, reconociendo que banking77 proviene de contexto de banca digital moderna y que mantener coherencia tonal es crÃ­tico para realismo de datos sintÃ©ticos.

La quinta decisiÃ³n fue expandir significativamente los schemas de cinco a once campos en conversations y de siete a diecisiete campos en time series, habilitando anÃ¡lisis mucho mÃ¡s ricos durante validaciÃ³n, bias detection y training.

---

### Estructura de Archivos Actual

La estructura del proyecto quedÃ³ organizada de la siguiente manera. En la raÃ­z tenemos data con subdirectorios raw para datos crudos, synthetic para datos generados, y reference para datasets de referencia que contiene customer_service_reference punto json y timeseries_reference punto json. TambiÃ©n tenemos docs con este archivo PROJECT_STATUS punto md y prÃ³ximamente DOMAIN3_FINANCIAL punto md, models para modelos entrenados, y logs para archivos de log.

En src tenemos generation con schemas punto py y templates que contiene customer_service_prompts punto py y timeseries_prompts punto py. TambiÃ©n tenemos utils con config punto py y download_references punto py, validation que estÃ¡ vacÃ­o por ahora, training que estÃ¡ vacÃ­o por ahora, y ui que estÃ¡ vacÃ­o por ahora.

---

### MÃ©tricas del DÃ­a 1

Comparando con el plan original, superamos significativamente las expectativas. En customer service expandimos de diez a setenta y siete intents, de dos a diez few-shot examples, de cinco a once campos en el schema, y agregamos dos funciones de validaciÃ³n. En time series expandimos de seis a diecisÃ©is series types, de uno a diez few-shot examples, de siete a diecisiete campos en el schema, y agregamos tres funciones de validaciÃ³n.

Implementamos bilingÃ¼ismo completo no planeado originalmente, tomamos una decisiÃ³n crÃ­tica de cambio de dataset basada en anÃ¡lisis tÃ©cnico, y establecimos arquitectura de validaciÃ³n built-in desde el diseÃ±o.

---

### PrÃ³ximos Pasos - DÃ­a 2

Para maÃ±ana implementaremos el motor de generaciÃ³n que usa AWS Bedrock. Crearemos el cliente de AWS con manejo de rate limiting y retry logic, implementaremos el generador de conversations usando los templates bilingÃ¼es, implementaremos el generador de time series, y agregaremos caching de prompts para optimizar costos.

El objetivo del dÃ­a dos es poder generar cien conversaciones de customer service y cien series temporales sintÃ©ticas exitosamente, validar que cumplen con los schemas de Pydantic, y guardar los datos generados en formato JSON lines en data slash synthetic.

---

### Notas TÃ©cnicas

Las versiones de dependencias instaladas son pydantic para validaciÃ³n de schemas, python-dotenv para cargar variables de entorno desde punto env, datasets y huggingface_hub para acceso a datasets de HuggingFace.

El archivo punto env debe contener AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, y AWS_REGION configurados con tus credenciales de AWS Bedrock. El archivo punto cursorrules define la arquitectura modular del proyecto y debe mantenerse actualizado si hacemos cambios arquitecturales.

Usamos uv como gestor de dependencias en lugar de pip, por lo que todos los comandos de instalaciÃ³n usan uv add en lugar de pip install. El archivo pyproject punto toml es gestionado automÃ¡ticamente por uv.

---

## ðŸ“… DÃ­a 2 â€” Motor de GeneraciÃ³n + AWS Bedrock

**Fecha:** 2024-12-20

### Resumen Ejecutivo

Completamos exitosamente la implementaciÃ³n del motor de generaciÃ³n con integraciÃ³n a AWS Bedrock. Se crearon los generadores CustomerServiceGenerator y TimeSeriesGenerator, ambos funcionales y validados con smoke tests y unit tests. Se resolvieron mÃºltiples problemas tÃ©cnicos incluyendo throttling de AWS y configuraciÃ³n de cross-region inference para Claude 3.5 Sonnet.

---

### Archivos Creados

| Archivo | DescripciÃ³n | LÃ­neas |
|---------|-------------|--------|
| `src/generation/generator.py` | BaseGenerator abstracto + CustomerServiceGenerator | ~500 |
| `src/generation/timeseries_generator.py` | TimeSeriesGenerator para series temporales | ~570 |
| `src/generation/__init__.py` | Exports de generadores y schemas | ~45 |
| `scripts/smoke_test.py` | Test de humo con throttling protection | ~220 |
| `scripts/test_batch_generation.py` | Script de prueba para batch de conversaciones | ~40 |
| `scripts/test_timeseries_generation.py` | Script de prueba para series temporales | ~106 |
| `tests/test_generators.py` | Unit tests con mocks (16 tests) | ~508 |

### Archivos Modificados

| Archivo | Cambio |
|---------|--------|
| `src/utils/config/loader.py` | Fix modelo Claude 3.5 Sonnet â†’ prefijo `us.` |
| `pyproject.toml` | Fix typo en lÃ­nea 33 (`s]` â†’ `]`) |

---

### ImplementaciÃ³n: BedrockClient

El cliente AWS Bedrock ya existÃ­a en `src/utils/aws_client.py` con las siguientes caracterÃ­sticas:

- **Rate limiting**: Control de tasa de requests
- **Retry logic**: 3 intentos con backoff exponencial (2s, 4s, 8s)
- **Manejo de errores**: Captura especÃ­fica de ThrottlingException y ValidationException
- **ConfiguraciÃ³n desde env**: Usa variables de entorno via `get_config()`

---

### ImplementaciÃ³n: CustomerServiceGenerator

Generador de conversaciones estilo Banking77 para neobanks/fintech.

**CaracterÃ­sticas:**
- Soporte para 77 intents de Banking77 organizados en 11 categorÃ­as
- BilingÃ¼e (inglÃ©s/espaÃ±ol)
- Few-shot prompting con 2 ejemplos por defecto
- ConfiguraciÃ³n de sentimiento, complejidad y emotion_arc
- ValidaciÃ³n automÃ¡tica de schema con `validate_conversation_schema()`
- CorrecciÃ³n automÃ¡tica de campos faltantes con `_fix_conversation_schema()`

**Estructura de salida:**
```python
{
    "conversation_id": "conv_abc123",
    "intent": "card_arrival",
    "category": "cards",
    "sentiment": "neutral",
    "complexity": "simple",
    "language": "en",
    "turn_count": 4,
    "customer_emotion_arc": "stable_neutral",
    "resolution_status": "resolved",
    "turns": [
        {"speaker": "customer", "text": "..."},
        {"speaker": "agent", "text": "..."}
    ],
    "metadata": {...}
}
```

---

### ImplementaciÃ³n: TimeSeriesGenerator

Generador de series temporales multi-dominio compatible con formato HuggingFace.

**CaracterÃ­sticas:**
- 16 tipos de series en 4 dominios:
  - **electricity** (50%): residential_consumption, commercial_consumption, industrial_load, grid_demand
  - **energy** (20%): solar_generation, wind_generation, gas_consumption, heating_demand
  - **sensors** (20%): temperature, pressure, humidity, air_quality
  - **financial** (10%): stock_price, crypto_price, exchange_rate, trading_volume
- Patrones configurables: seasonality (daily, weekly, annual), trends, anomalÃ­as
- Valores estandarizados (mean~0, std~1) para ML
- BilingÃ¼e (inglÃ©s/espaÃ±ol)

**Estructura de salida:**
```python
{
    "series_id": "ts_abc123",
    "domain": "electricity",
    "series_type": "residential_consumption",
    "frequency": "1H",
    "length": 24,
    "target": [0.2, 0.1, -0.1, ...],  # 24 valores
    "seasonality_types": ["daily"],
    "trend_type": "none",
    "anomaly_types": [],
    "metadata": {...}
}
```

---

### Smoke Test: Resultados

Se ejecutÃ³ `scripts/smoke_test.py` con configuraciÃ³n conservadora para evitar throttling:

**ConfiguraciÃ³n:**
- Batch size: 2 items
- Delay entre batches: 3 segundos
- Total: 10 conversaciones + 10 series temporales

**Resultados:**

| Dominio | Generados | Validados | Throttled |
|---------|-----------|-----------|-----------|
| Customer Service | 5/10 | 5/5 âœ“ | 5 |
| Time Series | 5/10 | 5/5 âœ“ | 5 |
| **Total** | **10/20** | **10/10** | **10** |

**Tiempo total:** 9.3 minutos (~558 segundos)

**Archivos generados:**
- `data/synthetic/customer_service_smoke_test.json` (5 conversaciones)
- `data/synthetic/timeseries_smoke_test.json` (5 series temporales)

**ConclusiÃ³n:** El 50% de pÃ©rdida se debe a throttling de AWS Bedrock, no a errores de cÃ³digo. Todos los items generados pasaron validaciÃ³n Pydantic.

---

### Unit Tests: Resultados

Se creÃ³ `tests/test_generators.py` con 16 tests usando mocks (sin llamadas reales a AWS).

**EjecuciÃ³n:**
```bash
uv run pytest tests/test_generators.py -v
```

**Resultados:** 16/16 passed en 5.32 segundos

| Clase de Test | Tests | Estado |
|---------------|-------|--------|
| TestCustomerServiceGenerator | 6 | âœ… Passed |
| TestTimeSeriesGenerator | 6 | âœ… Passed |
| TestJSONParsing | 2 | âœ… Passed |
| TestErrorHandling | 2 | âœ… Passed |

**Tests incluidos:**
1. `test_generate_single_returns_valid_structure`
2. `test_generate_single_with_specific_intent`
3. `test_generate_batch_returns_list`
4. `test_invalid_intent_handled_gracefully`
5. `test_generator_metrics`
6. `test_all_intents_are_valid` (verifica 77 intents)
7. `test_generate_single_returns_valid_structure` (time series)
8. `test_generate_single_with_specific_type`
9. `test_generate_batch_returns_list` (time series)
10. `test_generator_properties`
11. `test_get_series_types_for_domain`
12. `test_all_series_types_defined` (verifica 16 tipos)
13. `test_parse_json_in_markdown_block`
14. `test_parse_raw_json`
15. `test_generation_failure_raises_runtime_error`
16. `test_batch_continues_on_error`

---

### Problemas Encontrados y Soluciones

#### 1. ValidationException: Cross-Region Inference

**Error:**
```
ValidationException: Invocation of model ID anthropic.claude-3-5-sonnet-20241022-v2:0 
with on-demand throughput isn't supported.
```

**Causa:** Claude 3.5 Sonnet v2 requiere prefijo regional para cross-region inference.

**SoluciÃ³n:** Cambiar el model ID en `src/utils/config/loader.py`:
```python
# Antes
"claude_35_sonnet": "anthropic.claude-3-5-sonnet-20241022-v2:0"

# DespuÃ©s
"claude_35_sonnet": "us.anthropic.claude-3-5-sonnet-20241022-v2:0"
```

#### 2. ThrottlingException: Rate Limiting

**Error:**
```
ThrottlingException: Too many requests, please wait before trying again.
```

**Causa:** LÃ­mites de tasa de AWS Bedrock excedidos.

**SoluciÃ³n implementada:**
- Retry logic con backoff exponencial (2s, 4s, 8s)
- Delays entre batches en smoke test (3s)
- Flag `continue_on_error=True` para generaciÃ³n parcial

**RecomendaciÃ³n futura:** Solicitar aumento de cuota en AWS o usar batch sizes mÃ¡s pequeÃ±os.

#### 3. TypeError: from_config() missing argument

**Error:**
```
TypeError: BaseGenerator.from_config() missing 1 required positional argument: 'domain'
```

**Causa:** El mÃ©todo `from_config()` de BaseGenerator requerÃ­a `domain` pero las subclases no lo pasaban.

**SoluciÃ³n:** Override de `from_config()` en cada subclase:
```python
@classmethod
def from_config(cls) -> "CustomerServiceGenerator":
    client = BedrockClient.from_config()
    return cls(client=client, domain="customer_service")
```

#### 4. pyproject.toml Corrupted

**Error:**
```
TOML parse error at line 33: string values must be quoted
```

**Causa:** LÃ­nea 33 tenÃ­a `s]` en lugar de `]` (typo/corrupciÃ³n).

**SoluciÃ³n:** Corregir la lÃ­nea en `pyproject.toml`.

#### 5. UnicodeEncodeError en Windows

**Error:**
```
UnicodeEncodeError: 'charmap' codec can't encode character '\u2705'
```

**Causa:** Emoji âœ… no soportado en consola PowerShell por defecto.

**SoluciÃ³n:** Reemplazar emojis por texto ASCII `[OK]` en scripts.

---

### Git: Commits del DÃ­a 2

| Commit | DescripciÃ³n |
|--------|-------------|
| `e537a62` | Day 2: Add unit tests for generators (16 tests, mocked AWS) |
| `d591a78` | Day 2: Bedrock client + generators + smoke test |
| `63b4163` | Day 2: Bedrock client + generators + smoke test |

Todos los commits pusheados a `origin/main`.

---

### Checklist DÃ­a 2

| Entregable | Estado |
|------------|--------|
| Cliente AWS Bedrock con rate limiting y retry | âœ… |
| Clase base BaseGenerator | âœ… |
| CustomerServiceGenerator funcional | âœ… |
| TimeSeriesGenerator funcional | âœ… |
| Smoke test script | âœ… |
| Tests unitarios (16 tests) | âœ… |
| Fix cross-region inference Claude 3.5 | âœ… |
| Caching de prompts | â¬œ Pendiente |
| GeneraciÃ³n de 100 conversaciones + 100 series | â¬œ Parcial (10+10 en smoke test) |

---

### Recomendaciones para DÃ­a 3

#### Prioridad Alta

1. **Implementar Validation Module** (`src/validation/quality.py`)
   - Comparar datos sintÃ©ticos vs reference datasets
   - Calcular mÃ©tricas: completeness, consistency, realism, diversity
   - Usar los schemas QualityMetrics y BiasMetrics ya definidos

2. **Implementar Bias Detection** (`src/validation/bias.py`)
   - Detectar sesgos en distribuciÃ³n de sentimientos
   - Verificar cobertura de intents/series types
   - Alertas automÃ¡ticas si bias > threshold

#### Prioridad Media

3. **Generar Dataset Completo**
   - Ejecutar generaciÃ³n de 100 conversaciones + 100 series en batches pequeÃ±os
   - Guardar en `data/synthetic/` en formato JSON Lines
   - Considerar ejecutar overnight para evitar throttling

4. **Implementar Prompt Caching**
   - Cachear prompts frecuentes para reducir tokens
   - Almacenar en memoria o archivo local

#### Prioridad Baja

5. **UI BÃ¡sica en Streamlit**
   - Dashboard para visualizar datos generados
   - Botones para trigger generaciÃ³n manual
   - GrÃ¡ficas de mÃ©tricas de calidad

---

### Notas TÃ©cnicas DÃ­a 2

**Modelos Bedrock disponibles:**
- `us.anthropic.claude-3-5-sonnet-20241022-v2:0` (default, requiere prefijo `us.`)
- `anthropic.claude-3-sonnet-20240229-v1:0`
- `anthropic.claude-3-haiku-20240307-v1:0`
- `us.amazon.nova-pro-v1:0`

**LÃ­mites de throttling observados:**
- ~2-3 requests/minuto sin throttling
- Con batches de 2 + delay 3s: ~50% Ã©xito
- RecomendaciÃ³n: delay 5-10s para >80% Ã©xito

**Comandos Ãºtiles:**
```bash
# Ejecutar smoke test
uv run python -m scripts.smoke_test

# Ejecutar unit tests
uv run pytest tests/test_generators.py -v

# Ejecutar todos los tests (excluyendo integration)
uv run pytest -m "not integration"

# Verificar modelo configurado
uv run python -c "from src.utils.config import get_config; print(get_config().aws.bedrock_model_ids)"
```
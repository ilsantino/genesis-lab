# GENESIS-LAB ‚Äî Development Log (DEVLOG)

Este documento registra todos los avances diarios del proyecto GENESIS-LAB.  
Corresponde al D√≠a 1 de trabajo consolidado.

---

## üìÖ D√≠a 0 ‚Äî Setup inicial, arquitectura y configuraci√≥n AWS

### üîß Configuraci√≥n del entorno
- Creaci√≥n de estructura base del proyecto: `src/`, `ui/`, `tests/`, `data/`, `models/`, `notebooks/`.
- Configuraci√≥n de `pyproject.toml` como gestor principal de dependencias (usando uv).
- Creaci√≥n de `.cursorrules` para estandarizar estilo, arquitectura y comportamiento de la IA asistente.
- Instalaci√≥n de dependencias iniciales:
  - boto3  
  - streamlit  
  - python-dotenv  
  - pandas  
  - numpy
- Creaci√≥n del entorno virtual usando `uv`.

### ‚òÅÔ∏è AWS Setup completo
- Creaci√≥n de IAM User: `genesis-lab-dev-ilsantino`.
- Creaci√≥n de IAM Group con permisos m√≠nimos:
  - AmazonBedrockFullAccess  
  - AmazonS3FullAccess
- Generaci√≥n de Access Key y Secret Key.
- Instalaci√≥n correcta de AWS CLI v2 (solucionando problemas de PATH).
- Configuraci√≥n de credenciales v√≠a `aws configure`.
- Ajuste de regi√≥n a `us-east-1`.
- Validaci√≥n satisfactoria de Bedrock con: aws bedrock list-foundation-models --region us-east-1

### üîó GitHub Setup
- Creaci√≥n del repositorio remoto.
- Inicializaci√≥n de Git local.
- Resoluci√≥n del error ‚Äúfetch first‚Äù al hacer push.
- Sincronizaci√≥n correcta del repo.

### üñ• UI Base
- Creaci√≥n de `ui/app.py` y estructura inicial de p√°ginas en `ui/pages/`.
- Confirmaci√≥n de que Streamlit no requiere extensi√≥n en Cursor.

### üß± Decisiones Arquitect√≥nicas
- Uso de arquitectura modular en `src/`.
- Separaci√≥n estricta por responsabilidad.
- Nada de hardcodear secretos (uso obligatorio de `.env + config.py`).
- Bedrock como proveedor principal.
- Streamlit como UI inicial.
- Llama/Nova como modelos temporales hasta aprobaci√≥n de Claude.

---

## Estado actual del proyecto
- Entorno completamente funcional.
- AWS funcionando y Bedrock accesible.
- Proyecto inicializado con arquitectura limpia.
- Repo conectado a GitHub.
- UI b√°sica creada.

---
# GENESIS-LAB - Project Status

## D√≠a 1 Completado - Schemas, Reference Datasets, y Templates

Fecha: 2024-12-16

### Resumen Ejecutivo

Hemos completado exitosamente la fase de fundaci√≥n del proyecto, estableciendo todos los schemas de datos, descargando datasets de referencia de HuggingFace, y creando templates de prompts biling√ºes expandidos. Las mejoras estrat√©gicas realizadas durante la implementaci√≥n han elevado significativamente la calidad t√©cnica del proyecto m√°s all√° del plan original.

---

### Schemas de Datos Implementados

Creamos el archivo src slash generation slash schemas punto py con modelos Pydantic que definen la estructura de datos para todos los dominios del proyecto. Para el dominio de customer service, implementamos la clase CustomerServiceConversation que valida conversaciones multi-turn con diez intents diferentes, tres niveles de sentiment, y validaci√≥n autom√°tica de que la primera interacci√≥n siempre sea del cliente. Para el dominio de series temporales, implementamos la clase TimeSeries que valida series temporales con seis tipos diferentes de series, cuatro frecuencias posibles, y validaci√≥n autom√°tica de que los timestamps est√©n ordenados cronol√≥gicamente.

Adicionalmente definimos schemas para m√©tricas de calidad con QualityMetrics que incluye scores de completeness, consistency, realism y diversity, y para m√©tricas de bias con BiasMetrics que incluye distribuci√≥n demogr√°fica, distribuci√≥n de sentimiento, y cobertura de t√≥picos. Finalmente creamos DatasetMetadata para el registro de datasets con informaci√≥n de generaci√≥n, m√©tricas de calidad, m√©tricas de bias, y resultados de entrenamiento.

El tercer dominio financiero est√° documentado arquitecturalmente con FinancialTransaction pero no est√° implementado en el MVP, siguiendo la decisi√≥n estrat√©gica de profundizar en dos dominios en lugar de implementar superficialmente tres.

---

### Reference Datasets Descargados

Descargamos exitosamente dos datasets de referencia desde HuggingFace que usaremos para validaci√≥n de calidad y detecci√≥n de bias. Para customer service descargamos quinientos ejemplos del dataset banking77 que contiene consultas de servicios bancarios digitales clasificadas en setenta y siete intents diferentes. Este dataset se guard√≥ en data slash reference slash customer_service_reference punto json.

Para series temporales inicialmente planeamos usar ETDataset slash ett, pero identificamos durante la implementaci√≥n que este dataset solo conten√≠a dos series correlacionadas del mismo transformador el√©ctrico, lo cual era insuficiente para validaci√≥n estad√≠stica robusta. Tomamos la decisi√≥n estrat√©gica de cambiar a LeoTungAnh slash electricity_hourly, que proporciona trescientas setenta series independientes de consumo el√©ctrico de hogares portugueses reales. Descargamos cien series de las trescientas setenta disponibles, con quinientos puntos temporales cada una, y las guardamos en data slash reference slash timeseries_reference punto json.

Este cambio de dataset fue cr√≠tico porque con solo dos series correlacionadas no pod√≠amos calcular distribuciones estad√≠sticas significativas ni validar diversidad entre m√∫ltiples series sint√©ticas generadas. Con cien series independientes, el sistema de validaci√≥n podr√° comparar robustamente si los datos sint√©ticos muestran la misma variabilidad y patrones que datos reales de m√∫ltiples entidades independientes.

---

### Templates de Prompts - Customer Service

Creamos src slash generation slash templates slash customer_service_prompts punto py con templates biling√ºes expandidos que superan significativamente el dise√±o original. En lugar de los diez intents gen√©ricos planificados, integramos los setenta y siete intents de banking77 organizados en once categor√≠as funcionales, lo cual permite que nuestros datos sint√©ticos sean directamente comparables con el dataset de referencia durante la validaci√≥n.

Implementamos biling√ºismo completo con system prompts en ingl√©s y espa√±ol, y diez few-shot examples de alta calidad, cinco en cada idioma. El tono fue ajustado de corporativo tradicional a estilo neobank o fintech digital, reflejando que banking77 proviene de contexto de banca digital moderna similar a Revolut o Nubank, no de banca tradicional. Esta coherencia tonal es cr√≠tica para que los datos sint√©ticos sean realistas cuando se comparen con el reference dataset.

Expandimos el schema de conversaciones de cinco campos a once campos, agregando category para agrupar los setenta y siete intents, complexity con tres niveles, customer_emotion_arc para tracking de evoluci√≥n emocional durante la conversaci√≥n, y resolution_time_category para clasificar la eficiencia de resoluci√≥n en instant, quick, standard o extended.

Implementamos validaci√≥n built-in con las funciones validate_intent y validate_conversation_schema, siguiendo arquitectura de producci√≥n donde validamos en el punto de generaci√≥n para prevenir errores downstream. Tambi√©n agregamos build_batch_prompt para generar m√∫ltiples conversaciones en una sola llamada al LLM, optimizando costos de AWS Bedrock.

---

### Templates de Prompts - Time Series

Creamos src slash generation slash templates slash timeseries_prompts punto py con una estructura similar pero adaptada a datos num√©ricos temporales. Expandimos de seis tipos gen√©ricos a cuatro dominios estructurados con diecis√©is series types: electricity con cincuenta por ciento del peso incluyendo residential_consumption y grid_demand, energy con veinte por ciento incluyendo solar_generation y wind_generation, sensors con veinte por ciento incluyendo temperature y pressure, y financial con diez por ciento incluyendo stock_price y crypto_price.

Implementamos biling√ºismo con system prompts y diez few-shot examples, cinco en ingl√©s y cinco en espa√±ol. Expandimos el schema de series temporales de siete campos a diecisiete campos, agregando seasonality_types para especificar m√∫ltiples tipos de estacionalidad simult√°neos, trend_type para clasificar tendencias, anomaly_types para especificar tipos de anomal√≠as presentes, y domain_context para informaci√≥n espec√≠fica del dominio.

Cambiamos el formato target de lista de objetos con timestamp y value a lista simple de valores num√©ricos, haci√©ndolo compatible con el formato est√°ndar de HuggingFace que usa nuestro reference dataset. Esto permite comparaci√≥n directa durante validaci√≥n sin necesidad de transformaciones intermedias.

Implementamos tres funciones de validaci√≥n: validate_series_type para verificar que el tipo de serie sea v√°lido, validate_timeseries_schema para verificar la estructura del output, y validate_temporal_consistency para verificar que los timestamps est√©n correctamente espaciados y los patrones temporales sean coherentes.

---

### Configuraci√≥n Centralizada

Actualizamos src slash utils slash config punto py con configuraci√≥n detallada por dominio. Para customer service especificamos el reference dataset como banking77, los diez intents originales m√°s una nota de que los templates usan setenta y siete intents, y par√°metros de generaci√≥n con temperature cero punto siete, max_tokens mil, y top_p cero punto nueve.

Para time series especificamos el reference dataset como electricity, los seis series types con frecuencias de one minute, five minutes, one hour y one day, y par√°metros de generaci√≥n con temperature m√°s baja de cero punto cinco para mayor consistencia num√©rica, max_tokens dos mil, y top_p cero punto ochenta y cinco.

Configuramos thresholds de validaci√≥n con m√≠nimos de noventa y cinco por ciento para completeness, noventa por ciento para consistency, ochenta y cinco por ciento para realism, ochenta por ciento para diversity, y ochenta y cinco puntos cero para overall quality score. Para bias detection establecimos m√°ximo de cero punto tres para sentiment imbalance y m√≠nimo de cero punto siete para topic coverage.

Definimos la configuraci√≥n de training con test size de veinte por ciento, validation size de diez por ciento, random state cuarenta y dos, y modelos habilitados incluyendo logistic regression y xgboost, dejando random forest deshabilitado para el MVP.

---

### Decisiones Estrat√©gicas Clave

Durante la implementaci√≥n tomamos varias decisiones estrat√©gicas que mejoraron significativamente el proyecto. La primera fue integrar completamente los setenta y siete intents de banking77 en lugar de usar diez intents gen√©ricos, lo cual alinea la generaci√≥n sint√©tica con el dataset de referencia usado en evaluaci√≥n, facilitando comparaciones directas y validaci√≥n rigurosa.

La segunda decisi√≥n fue implementar biling√ºismo completo en ingl√©s y espa√±ol, reconociendo que M√©xico y Espa√±a son mercados objetivo de iaGO y que proyectos biling√ºes son raros y valiosos en portfolios acad√©micos. Esto agrega complejidad t√©cnica pero tambi√©n demuestra capacidad de trabajar con m√∫ltiples idiomas.

La tercera decisi√≥n fue cambiar de ETT a electricity_hourly para series temporales, basada en el an√°lisis cr√≠tico de que dos series correlacionadas eran insuficientes para validaci√≥n estad√≠stica robusta. Este cambio asegura que podemos validar adecuadamente la diversidad y realismo de datos sint√©ticos generados.

La cuarta decisi√≥n fue ajustar el tono de corporativo a neobank o fintech digital, reconociendo que banking77 proviene de contexto de banca digital moderna y que mantener coherencia tonal es cr√≠tico para realismo de datos sint√©ticos.

La quinta decisi√≥n fue expandir significativamente los schemas de cinco a once campos en conversations y de siete a diecisiete campos en time series, habilitando an√°lisis mucho m√°s ricos durante validaci√≥n, bias detection y training.

---

### Estructura de Archivos Actual

La estructura del proyecto qued√≥ organizada de la siguiente manera. En la ra√≠z tenemos data con subdirectorios raw para datos crudos, synthetic para datos generados, y reference para datasets de referencia que contiene customer_service_reference punto json y timeseries_reference punto json. Tambi√©n tenemos docs con este archivo PROJECT_STATUS punto md y pr√≥ximamente DOMAIN3_FINANCIAL punto md, models para modelos entrenados, y logs para archivos de log.

En src tenemos generation con schemas punto py y templates que contiene customer_service_prompts punto py y timeseries_prompts punto py. Tambi√©n tenemos utils con config punto py y download_references punto py, validation que est√° vac√≠o por ahora, training que est√° vac√≠o por ahora, y ui que est√° vac√≠o por ahora.

---

### M√©tricas del D√≠a 1

Comparando con el plan original, superamos significativamente las expectativas. En customer service expandimos de diez a setenta y siete intents, de dos a diez few-shot examples, de cinco a once campos en el schema, y agregamos dos funciones de validaci√≥n. En time series expandimos de seis a diecis√©is series types, de uno a diez few-shot examples, de siete a diecisiete campos en el schema, y agregamos tres funciones de validaci√≥n.

Implementamos biling√ºismo completo no planeado originalmente, tomamos una decisi√≥n cr√≠tica de cambio de dataset basada en an√°lisis t√©cnico, y establecimos arquitectura de validaci√≥n built-in desde el dise√±o.

---

### Pr√≥ximos Pasos - D√≠a 2

Para ma√±ana implementaremos el motor de generaci√≥n que usa AWS Bedrock. Crearemos el cliente de AWS con manejo de rate limiting y retry logic, implementaremos el generador de conversations usando los templates biling√ºes, implementaremos el generador de time series, y agregaremos caching de prompts para optimizar costos.

El objetivo del d√≠a dos es poder generar cien conversaciones de customer service y cien series temporales sint√©ticas exitosamente, validar que cumplen con los schemas de Pydantic, y guardar los datos generados en formato JSON lines en data slash synthetic.

---

### Notas T√©cnicas

Las versiones de dependencias instaladas son pydantic para validaci√≥n de schemas, python-dotenv para cargar variables de entorno desde punto env, datasets y huggingface_hub para acceso a datasets de HuggingFace.

El archivo punto env debe contener AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, y AWS_REGION configurados con tus credenciales de AWS Bedrock. El archivo punto cursorrules define la arquitectura modular del proyecto y debe mantenerse actualizado si hacemos cambios arquitecturales.

Usamos uv como gestor de dependencias en lugar de pip, por lo que todos los comandos de instalaci√≥n usan uv add en lugar de pip install. El archivo pyproject punto toml es gestionado autom√°ticamente por uv.
